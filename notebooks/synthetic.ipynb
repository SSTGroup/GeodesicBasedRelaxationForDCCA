{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd47302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from GeodesicRelaxationDCCA.algorithms.correlation import CCA\n",
    "from GeodesicRelaxationDCCA.algorithms.correlation_residual import canonical_correlations, chordal_distance\n",
    "from GeodesicRelaxationDCCA.algorithms.losses_metrics import EpochWatchdog, EmptyWatchdog\n",
    "\n",
    "from GeodesicRelaxationDCCA.data.synthetic import SyntheticData\n",
    "from GeodesicRelaxationDCCA.experiments.synthetic import SynthDeepCCAExperiment, SynthDeepCCASlackExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_network(dataprov, network):\n",
    "    for data in dataprov.training_data:\n",
    "        netw_output = network(data)\n",
    "\n",
    "    gt_signal_0 = dataprov.z_0\n",
    "    gt_signal_1 = dataprov.z_1\n",
    "\n",
    "    if 'rrcca_view_0' in netw_output.keys():\n",
    "        latent_view_0 = tf.transpose(netw_output['rrcca_view_0'])\n",
    "        latent_view_1 = tf.transpose(netw_output['rrcca_view_1'])\n",
    "    elif 'cca_view_0' in netw_output.keys():\n",
    "        latent_view_0 = netw_output['cca_view_0']\n",
    "        latent_view_1 = netw_output['cca_view_1']\n",
    "\n",
    "    _, _, _, _, ccor_0, _, _ = CCA(gt_signal_0, latent_view_0, 2)\n",
    "    _, _, _, _, ccor_1, _, _ = CCA(gt_signal_1, latent_view_1, 2)\n",
    "\n",
    "    dist_0 = 1 - tf.math.reduce_mean(ccor_0)\n",
    "    dist_1 = 1 - tf.math.reduce_mean(ccor_1)\n",
    "    dist_avg = (dist_0+dist_1)/2\n",
    "\n",
    "    correlations = canonical_correlations(latent_view_0, latent_view_1, 2, 0)\n",
    "    corr_avg = tf.math.reduce_mean(correlations)\n",
    "    \n",
    "    return {\n",
    "        'dist_0': dist_0.numpy(),\n",
    "        'dist_1': dist_1.numpy(),\n",
    "        'dist_avg': dist_avg.numpy(),\n",
    "        'corr': correlations.numpy(),\n",
    "        'corr_avg': corr_avg.numpy(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cba149",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'tmp'\n",
    "\n",
    "if not os.path.exists(root_dir):\n",
    "    os.mkdir(root_dir)\n",
    "\n",
    "# Load synthetic data\n",
    "syn_dataprovider = SyntheticData.generate(\n",
    "    num_samples=200,\n",
    "    batch_size=200,\n",
    "    correlations=[0.6, 0.6],\n",
    "    num_channels=2,\n",
    "    non_lin_type='channel_wise'\n",
    ")\n",
    "\n",
    "# Save dataset\n",
    "syn_dataprovider.save(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, ccor, _, _ = CCA(syn_dataprovider.z_0, syn_dataprovider.z_1, 2)\n",
    "gt_angles = tf.math.acos(ccor)\n",
    "gt_distance = tf.linalg.norm(tf.math.sin(gt_angles)) / tf.sqrt(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c591f1",
   "metadata": {},
   "source": [
    "## DCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063014cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcca_results = list()\n",
    "\n",
    "for _ in range(5):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    exp = SynthDeepCCAExperiment(\n",
    "        log_dir=os.path.join(root_dir, 'slack_ref'), \n",
    "        encoder_config_v1=[(256, 'sigmoid'), (256, 'sigmoid'), (2, None)],\n",
    "        encoder_config_v2=[(256, 'sigmoid'), (256, 'sigmoid'), (2, None)],\n",
    "        dataprovider=syn_dataprovider,\n",
    "        shared_dim=2,\n",
    "        lambda_rad=0,\n",
    "        topk=1,\n",
    "        max_perc=1,\n",
    "        lambda_l1=0,\n",
    "        lambda_l2=1e-4,\n",
    "        cca_reg=1e-4,\n",
    "        eval_epochs=5, \n",
    "        val_default_value=1.0,\n",
    "        convergence_threshold=0.001,\n",
    "        optimizer=opt\n",
    "    )\n",
    "\n",
    "    exp.train_multiple_epochs(2000)\n",
    "    \n",
    "    exp.save()\n",
    "    \n",
    "    dcca_results.append(eval_network(syn_dataprovider, exp.architecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1683da",
   "metadata": {},
   "source": [
    "## RDCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrcca_results = dict()\n",
    "\n",
    "for residual in [0.0, 0.1, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    rrcca_results[residual] = list()\n",
    "    for _ in range(5):\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        exp = SynthDeepCCASlackExperiment(\n",
    "            log_dir=os.path.join(root_dir, 'slack'),\n",
    "            encoder_config_v1=[(256, 'sigmoid'), (256, 'sigmoid'), (2, None)],\n",
    "            encoder_config_v2=[(256, 'sigmoid'), (256, 'sigmoid'), (2, None)],\n",
    "            dataprovider=syn_dataprovider,\n",
    "            shared_dim=2,\n",
    "            residual=residual,\n",
    "            corr_reg=1e-6,\n",
    "            lambda_l1=0,\n",
    "            lambda_l2=1e-6,\n",
    "            eval_epochs=5,\n",
    "            val_default_value=1.0,\n",
    "            convergence_threshold=0.001,\n",
    "            optimizer=opt\n",
    "        )\n",
    "\n",
    "        exp.train_multiple_epochs(num_epochs=2000, num_inner_epochs=100, epsilon_inner_epochs=1e-10)\n",
    "        \n",
    "        exp.save()\n",
    "        \n",
    "        rrcca_results[residual].append(eval_network(syn_dataprovider, exp.architecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab5fcf",
   "metadata": {},
   "source": [
    "## CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in syn_dataprovider.training_data:\n",
    "    pass\n",
    "\n",
    "Ax, Ay, epsilon, omega, _, _, _ = CCA(data['nn_input_0'], data['nn_input_1'], 2)\n",
    "\n",
    "gt_signal_0 = syn_dataprovider.z_0\n",
    "gt_signal_1 = syn_dataprovider.z_1\n",
    "\n",
    "_, _, _, _, ccor_0, _, _ = CCA(gt_signal_0, tf.transpose(epsilon), 2)\n",
    "_, _, _, _, ccor_1, _, _ = CCA(gt_signal_1, tf.transpose(omega), 2)\n",
    "\n",
    "dist_0 = 1 - tf.math.reduce_mean(ccor_0)\n",
    "dist_1 = 1 - tf.math.reduce_mean(ccor_1)\n",
    "dist_avg = (dist_0+dist_1)/2\n",
    "\n",
    "correlations = canonical_correlations(tf.transpose(epsilon), tf.transpose(omega), 2, 0)\n",
    "corr_avg = tf.math.reduce_mean(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eef2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (system)",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
